@inproceedings{stockdill17,
	Author = {Stockdill, Aaron and Neshatian, Kourosh},
	Booktitle = {2017 International Conference on Image and Vision Computing New Zealand (IVCNZ)},
	Doi = {10.1109/IVCNZ.2017.8402482},
	Pages = {1--7},
	Title = {Simulating neuromorphic reservoir computing: Abstract feed-forward hardware models},
	Url = {http://dx.doi.org/10.1109/IVCNZ.2017.8402482},
	Year = {2016},
	Month = {December},
    copyright = {The final publication is available through IEEEXplore via <a target='_blank' href='http://dx.doi.org/10.1109/IVCNZ.2017.8402482'>http://dx.doi.org/10.1109/IVCNZ.2017.8402482</a>},
    Abstract = {Recent developments of unconventional hardware using memristors and atomic switch networks has led to renewed interest in hardware neuromorphic solutions. Most hardware models rely upon a reservoir neural network as the basis of any learning, but the distinct differences between software implementations and hardware reality mean what we take for granted in traditional software reservoirs - such as cycles, loops, infinite energy, and discrete time - may be severely limited or unavailable in hardware, raising questions about how a hardware implementation would perform and how to potentially overcome these limitations. Proposed hardware additions, such as an echoer or an input delay mechanism, address some of these limitations.}}
